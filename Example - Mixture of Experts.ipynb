{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - using Mixture of Experts layer to define Keras model\n",
    "\n",
    "This example illustrates a practical application how multiple experts can be combined together to build an effective mixture model. \n",
    "\n",
    "In this example, a gating model (defined a single-layer neural network with noisy version of softmax activation), would channel each example to exactly 2 experts, and combine their results with corresponding weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import tensor2tensor\n",
    "from tensor2tensor.utils.expert_utils import *\n",
    "from customutils.CustomLayers import MixtureOfExpertsLayer\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0329414499386727\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data for practice\n",
    "X = np.random.normal(scale = 1, size = 10**6).reshape(-1,20) #50K observations and 20 variables\n",
    "y = X[:,0] + X[:,1] + X[:,0]* X[:,1]\n",
    "X.shape, y.shape\n",
    "print(np.var(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture that would be considered as single expert\n",
    "class TimeLimit(keras.callbacks.Callback):\n",
    "    def __init__(self, time_limit_seconds, verbose = 1):\n",
    "        self.time_limit_seconds = time_limit_seconds\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.time_start = time.time()\n",
    "        \n",
    "    def on_epoch_end(self,epoch,logs):\n",
    "        if time.time() >= self.time_start + self.time_limit_seconds:\n",
    "            self.model.stop_training = True\n",
    "            if self.verbose > 0: print('Training terminated after epoch ', epoch+1)\n",
    "\n",
    "        \n",
    "callbacks_list = []\n",
    "\n",
    "def build_model(input_dim = 20, hidden_layer_sizes = [4,1], lr_init = 0.1, lr_decay = 0.001, activation = 'tanh', output_dim = 1, random_state = 7, early_stopping = False, max_fit_time = 60, compile = False):\n",
    "    tf.set_random_seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "    inputs  = keras.layers.Input((input_dim,), dtype='float32')\n",
    "    for idx, hidden_layer_size in enumerate(hidden_layer_sizes):\n",
    "        if idx == 0: hidden = keras.layers.Dense(hidden_layer_size, activation = activation)(inputs)\n",
    "        else:        hidden = keras.layers.Dense(hidden_layer_size, activation = activation)(hidden)\n",
    "    outputs = keras.layers.Dense(output_dim)(hidden) # no activation for the last layer\n",
    "    model   = keras.Model(inputs, outputs)\n",
    "    #model.summary()\n",
    "    if compile ==True:\n",
    "        model.compile(loss = 'mean_squared_error', optimizer = keras.optimizers.Adam(lr=lr_init, decay = lr_decay))\n",
    "\n",
    "    # add callbacks to be utilized by the fit function - could check if 'callbacks_list' not in globals() \n",
    "    global callbacks_list \n",
    "    if 'callbacks_list' in globals(): callbacks_list.clear()\n",
    "    \n",
    "    if early_stopping == True:\n",
    "        callbacks_list.append(keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=2, verbose=1, mode='auto'))\n",
    "    if max_fit_time: \n",
    "        callbacks_list.append(TimeLimit(max_fit_time))\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MoE_as_model(n_experts, input_dim, output_dim, model_function, use_top_K = None, loss = 'mse', optimizer = 'rmsprop', sparse_inputs = False, random_state = 7):\n",
    "    # initialize models    \n",
    "    models = []\n",
    "    for i in range(n_experts):\n",
    "        with tf.name_scope('Expert_' + str(1+i)):\n",
    "            model = model_function(random_state = 13 + i * random_state) # creates a separate expert\n",
    "            models.append(model)\n",
    "    \n",
    "    #inputs = keras.layers.Input((input_dim,), dtype='float32')\n",
    "    inputs = keras.layers.Input((input_dim,), dtype='float', sparse = sparse_inputs)\n",
    "    outputs= MixtureOfExpertsLayer(models, use_top_K = use_top_K, input_dim = input_dim)(inputs)\n",
    "    model  = keras.Model(inputs, outputs)\n",
    "    model.compile(loss = loss, optimizer = optimizer)\n",
    "    \n",
    "    #could also consider returning KerasRegressor wrapper\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "mixture_of_experts_layer_1 ( ((None,), 1)              6410      \n",
      "=================================================================\n",
      "Total params: 6,410\n",
      "Trainable params: 6,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "keras_model = build_MoE_as_model(\n",
    "        10,                                                                   # number of experts to train\n",
    "        20,                                                                   # input dimensions\n",
    "        1,                                                                    # output dimensions \n",
    "        lambda **kwargs: build_model(hidden_layer_sizes = [20,10], **kwargs), # individual experts\n",
    "        use_top_K = 2,                                                        # number of experts to use for each record \n",
    "        optimizer = keras.optimizers.Adam(lr = 0.01),                         # optimizer\n",
    "        sparse_inputs = False                                                 # whether each model would use sparse inputs  \n",
    ")\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.3213\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.6242\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.2034\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.0951\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.0619\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0469\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0372\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0300\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0254\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0211: 0s - lo\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0180\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0153\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0140\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0126\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0114\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0103\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.0098\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0087\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0080\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0082\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0081\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0068\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0066\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0069\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0064\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0067\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0061\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0062\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0058\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.0059\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0060\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0060\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0066\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0063\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0052\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0051\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0049\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.0057\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0051\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0050\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0050\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0057\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0057\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0054\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0056\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0046\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0048\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0059\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0053\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0055\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0052\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0047\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0042\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0055\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0052: 0\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0060\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.0060\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0061\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.0058\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0056\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0054\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0051\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0044\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0049\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0043\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0046\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0050\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0049\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0054\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0050\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.0050\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0057\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0055\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0053\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0052\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0062\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0049\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0050\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0051\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0052\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0049\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0051\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0050\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0049\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0051\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0052\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0047\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 1s 19us/step - loss: 0.0050\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0058\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0055\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0047\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0045\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0045\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0045\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0046\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0046\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0044\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.0052\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0061\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4c2234240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model to the synthetic data generated above\n",
    "keras_model.fit(X,y, batch_size = 2**10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987138291250041"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report model fit metrics\n",
    "import sklearn\n",
    "sklearn.metrics.r2_score(keras_model.predict(X, batch_size = 10**20), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is attaining about 99.9% $R^2$ after less than 100 epochs (about 1 second per epoch on GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
